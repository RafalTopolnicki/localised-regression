{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a550b9b-859a-42a2-96e3-34e8b71c96a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run \n",
    "# jupyter nbconvert --to script 2d_linear_confidenceintervals.ipynb\n",
    "# to convert to .py strict and run the .py!\n",
    "import scipy.stats as ss\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV\n",
    "from sklearn.svm import SVR  # for building SVR model\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from BMR.bmr import *\n",
    "from pyearth import Earth\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "482dc2dd-1d90-4fbb-b975-d4b913d57d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 1\n",
    "\n",
    "def gen_model(X, a, b, c, d, e):\n",
    "    return a*X[:, 0] + b*X[:, 1] + c*X[:, 0]**2 + d*X[:, 1]**2 + e*X[:, 0]*X[:, 1]\n",
    "def gen_data(n, a, b, c, d, e, eps):\n",
    "    if Xdist == 'U':\n",
    "        rng = ss.uniform(loc=-4, scale=8)\n",
    "    if Xdist == 'N':\n",
    "        rng = ss.norm()\n",
    "    X = rng.rvs(size=(n, 2))\n",
    "    y = gen_model(X=X, a=a, b=b, c=c, d=d, e=e)\n",
    "    if eps>0:\n",
    "        y += ss.norm(loc=0, scale=eps).rvs(size=(n, ))\n",
    "    y = y[:, np.newaxis]\n",
    "    return X, y\n",
    "\n",
    "def get_mars_params(x, y):\n",
    "    param_grid = {\"max_terms\": [0, 1, 2, 3, 5, 10], \"max_degree\": [0, 1, 2, 3, 4]}\n",
    "    mars = Earth()\n",
    "    sh = GridSearchCV(mars, param_grid, cv=3, n_jobs=n_jobs).fit(x, y)\n",
    "    return sh.best_params_, sh.cv_results_\n",
    "\n",
    "def get_svr_params(x, y):\n",
    "    param_grid = {\"C\": [0.1, 1, 10, 100, 300, 500], \"degree\": [1, 2, 3, 4],\n",
    "                  \"epsilon\": [0, 0.0001, 0.001, 0.01, 0.1, 1], \"kernel\": ['linear', 'rbf']}\n",
    "    svr = SVR(kernel=\"rbf\")\n",
    "    sh = HalvingGridSearchCV(svr, param_grid, cv=3, factor=3, n_jobs=n_jobs).fit(x, y)\n",
    "    return sh.best_params_, sh.cv_results_\n",
    "\n",
    "def get_bmr_params(x, y, M, degree, substitution_policy=\"nearest\", in_ball_model='linear'):\n",
    "    n_pts = x.shape[0]\n",
    "    epsilons = [0.1, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0]\n",
    "    min_n_pts = [max(int(n_pts*np.pi*(2*e)**2/(8*8)), 4) for e in epsilons]\n",
    "    param_grid = {\n",
    "        \"epsilon\": epsilons,\n",
    "        \"min_n_pts\": min_n_pts,\n",
    "    }\n",
    "    bmr = BMR(min_n_pts=10, M=M, substitution_policy=substitution_policy, \n",
    "              degree=degree, epsilon=0.5, in_ball_model=in_ball_model)\n",
    "    #sh = HalvingGridSearchCV(bmr, param_grid, cv=3, factor=3, n_jobs=n_jobs).fit(x, y)\n",
    "    sh = GridSearchCV(bmr, param_grid, cv=3, n_jobs=n_jobs, verbose=3).fit(x, y)\n",
    "    params = sh.best_params_\n",
    "    params['M'] = M\n",
    "    params['substitution_policy'] = substitution_policy\n",
    "    params['in_ball_model'] = in_ball_model\n",
    "    params['degree'] = degree\n",
    "    return params, sh.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81dee6c5-a9d4-43b6-942f-1081be7acf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in which prediction is made\n",
    "grid_points = np.arange(-4, 4.1, 0.2)\n",
    "mesh_X, mesh_Y = np.meshgrid(grid_points, grid_points)\n",
    "mesh_pts = np.array([np.ravel(mesh_X), np.ravel(mesh_Y)]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c1f6b0-5493-43c1-b690-a3f4798a8d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(n, a, b, c, d, e, eps, mcloops=100, substitution_policy='nearest', degree=1):\n",
    "    alpha = 0.05\n",
    "    filename_base = f'{OUTPUT_DIR}/BMR2d_n={n}_a={a:.3f}_b={b:.3f}_c={c:.3f}_d{d:.3f}_e{e:.3f}_eps={eps:.4f}_{substitution_policy}_X{Xdist}_degree{degree}'\n",
    "    filename_csv = f'{filename_base}.csv'\n",
    "    filename_pickle = f'{filename_base}.pickle'\n",
    "    \n",
    "    X_pred = mesh_pts\n",
    "    y_true = gen_model(X_pred, a, b, c, d, e)\n",
    "\n",
    "    #generate one sample to set method parameters\n",
    "    X, y = gen_data(n=n, a=a, b=b, c=c, d=d, e=e, eps=eps)\n",
    "    bmr_params, bmr_cv_results = get_bmr_params(X, y, M=20, degree=degree, substitution_policy=substitution_policy)\n",
    "    mars_params, mars_cv_results = get_mars_params(X, y[:, 0])\n",
    "    svr_params, svr_cv_results = get_svr_params(X, y[:, 0])\n",
    "    # bmr_params = {'epsilon': 1.5, 'min_n_pts': 100, 'M': 20, 'substitution_policy': 'nearest', 'in_ball_model': 'linear', 'degree': 1}\n",
    "    # mars_params = {}\n",
    "    # svr_params = {}\n",
    "    \n",
    "    # save params to file\n",
    "    pickle.dump([bmr_params, mars_params, svr_params, bmr_cv_results, mars_cv_results, svr_cv_results], open(filename_pickle, 'wb'))\n",
    "    \n",
    "    # init methods\n",
    "    methods_labels = ['LR', 'BMR', 'MARS', 'SVR']\n",
    "    \n",
    "    results = {}\n",
    "    betas = {}\n",
    "    intercepts = {}\n",
    "    for method_label in methods_labels:\n",
    "        results[method_label] = []\n",
    "        betas[method_label] = []\n",
    "        intercepts[method_label] = []\n",
    "\n",
    "    for loop in range(mcloops):\n",
    "        #if loop % 10 == 0:\n",
    "        print(f'Running loop {loop}/{mcloops} for {filename_csv}')\n",
    "        \n",
    "        # run all methods on new data set\n",
    "        X, y = gen_data(n=n, a=a, b=b, c=c, d=d, e=e, eps=eps)\n",
    "        methods = [LinearRegression(), BMR(**bmr_params), Earth(**mars_params), SVR(**svr_params)]\n",
    "        for method_label, method in zip(methods_labels, methods):\n",
    "            if method_label == 'SVR':\n",
    "                method.fit(X, y[:, 0])\n",
    "            else:\n",
    "                method.fit(X, y)\n",
    "            pred = method.predict(X_pred)\n",
    "            if len(pred.shape) > 1:\n",
    "                pred = pred[:, 0]\n",
    "            results[method_label].append(pred)\n",
    "            # save coefficients\n",
    "            if method_label == 'BMR':\n",
    "                beta, intercept = method.coefficients(X_pred)\n",
    "                betas['BMR'].append(beta)\n",
    "                intercepts['BMR'].append(intercept)\n",
    "            if method_label == 'LR':\n",
    "                betas['LR'].append(method.coef_)\n",
    "                intercepts['LR'].append(method.intercept_)\n",
    "\n",
    "    coeff = {}\n",
    "    n_betas = np.array(betas['BMR']).shape[2]\n",
    "    print(n_betas)\n",
    "    for beta in range(n_betas):\n",
    "        coeff[f'BMR_beta{beta+1}_mean'] = np.mean(np.array(betas['BMR']), axis=0)[:, beta] \n",
    "        coeff[f'BMR_beta{beta+1}_low'] = np.quantile(np.array(betas['BMR']), q=alpha/2, axis=0)[:, beta] \n",
    "        coeff[f'BMR_beta{beta+1}_up'] = np.quantile(np.array(betas['BMR']), q=1-alpha/2, axis=0)[:, beta]\n",
    "        coeff[f'BMR_beta{beta+1}_len'] =  np.array(coeff[f'BMR_beta{beta+1}_up'])-np.array(coeff[f'BMR_beta{beta+1}_low'])\n",
    "    coeff['BMR_I_mean'] = np.mean(np.array(intercepts['BMR']), axis=0) \n",
    "    coeff['BMR_I_low'] = np.quantile(np.array(intercepts['BMR']), q=alpha/2, axis=0) \n",
    "    coeff['BMR_I_up'] = np.quantile(np.array(intercepts['BMR']), 1-alpha/2, axis=0) \n",
    "    coeff['BMR_I_len'] = np.array(coeff['BMR_I_up']) - np.array(coeff['BMR_I_low'])\n",
    "    coeff['LR_beta1_mean'] = np.mean(np.array(betas['LR']), axis=0)[:, 0].tolist()*X_pred.shape[0]\n",
    "    coeff['LR_beta1_low'] = np.quantile(np.array(betas['LR']), q=alpha/2, axis=0)[:, 0].tolist()*X_pred.shape[0]\n",
    "    coeff['LR_beta1_up'] = np.quantile(np.array(betas['LR']), q=1-alpha/2, axis=0)[:, 0].tolist()*X_pred.shape[0]\n",
    "    coeff['LR_beta1_len'] = np.array(coeff['LR_beta1_up']) - np.array(coeff['LR_beta1_low'])\n",
    "    coeff['LR_beta2_mean'] = np.mean(np.array(betas['LR']), axis=0)[:, 1].tolist()*X_pred.shape[0]\n",
    "    coeff['LR_beta2_low'] = np.quantile(np.array(betas['LR']), q=alpha/2, axis=0)[:, 1].tolist()*X_pred.shape[0]\n",
    "    coeff['LR_beta2_up'] = np.quantile(np.array(betas['LR']), q=1-alpha/2, axis=0)[:, 1].tolist()*X_pred.shape[0]\n",
    "    coeff['LR_beta2_len'] = np.array(coeff['LR_beta2_up']) - np.array(coeff['LR_beta2_low'])\n",
    "    coeff['LR_I_mean'] = np.mean(np.array(intercepts['LR']), axis=0).tolist()*X_pred.shape[0]\n",
    "    coeff['LR_I_low'] = np.quantile(np.array(intercepts['LR']), q=alpha/2, axis=0).tolist()*X_pred.shape[0]\n",
    "    coeff['LR_I_up'] = np.quantile(np.array(intercepts['LR']), q=1-alpha/2, axis=0).tolist()*X_pred.shape[0]\n",
    "    coeff['LR_I_len'] = np.array(coeff['LR_I_up']) - np.array(coeff['LR_I_low'])\n",
    "       \n",
    "    # collect the results and prepare the csv\n",
    "    df0 = pd.DataFrame([mesh_pts[:, 0], mesh_pts[:, 1]]).transpose()\n",
    "    df0.columns = ['x', 'y']\n",
    "    dfs = [df0]\n",
    "    for method_label in methods_labels:\n",
    "        dat = np.array(results[method_label]).transpose()\n",
    "        ci_low = np.quantile(dat, q=alpha/2, axis=1)\n",
    "        ci_up = np.quantile(dat, q=1-alpha/2, axis=1)\n",
    "        mse = np.mean((dat - y_true.reshape(-1,1))**2, axis=1)\n",
    "        df = pd.DataFrame([ci_low, ci_up, ci_up-ci_low, mse]).transpose()\n",
    "        df.columns = [f'{method_label}_CI_low', f'{method_label}_CI_up', f'{method_label}_CI_len', f'{method_label}_MSE']\n",
    "        dfs.append(df)\n",
    "    # add DataFrame containing coefficients\n",
    "    dfs.append(pd.DataFrame(coeff))\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "    df.to_csv(filename_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a9e1e-bde0-4ed7-916c-25f293a3d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n\", type=int, required=True, help=\"sample size\")\n",
    "parser.add_argument(\"--a\", type=float, required=True, help=\"param a\")\n",
    "parser.add_argument(\"--b\", type=float, required=True, help=\"param b\")\n",
    "parser.add_argument(\"--c\", type=float, required=True, help=\"param c\")\n",
    "parser.add_argument(\"--d\", type=float, required=True, help=\"param d\")\n",
    "parser.add_argument(\"--e\", type=float, required=True, help=\"param e\")\n",
    "parser.add_argument(\"--eps\", type=float, required=True, help=\"noise\")\n",
    "parser.add_argument(\"--M\", type=int, required=True, help=\"number of MC loops\")\n",
    "parser.add_argument(\"--X\", type=str, required=True, help=\"X distribution\")\n",
    "parser.add_argument(\"--mode\", type=str, required=True, help=\"substitution policy\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "OUTPUT_DIR = 'csv'\n",
    "\n",
    "Xdist = args.X\n",
    "if Xdist not in ['U', 'N']:\n",
    "    raise ValueError(f'--X must be U or N. Found {Xdist}')\n",
    "\n",
    "run_experiment(n=args.n, a=args.a, b=args.b, c=args.c, d=args.d, e=args.e, eps=args.eps, mcloops=args.M, substitution_policy=args.mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
